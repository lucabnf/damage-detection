{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Interview task**\n",
    "Create a jupyter notebook to train a segmentation model for damage detection based on the given training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luca/interview/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/luca/interview/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/luca/interview/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/luca/interview/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/luca/interview/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/luca/interview/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "import cv2\n",
    "import re\n",
    "from mrcnn.visualize import display_instances\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import Mask RCNN\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = os.path.join(\".\", \"dataset\")\n",
    "test_images = os.path.join(\".\", \"test\")\n",
    "logs = weights_path = os.path.join(\".\", \"logs\")\n",
    "weights_path = os.path.join(\".\", \"mask_rcnn_coco.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Configurations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomConfig(Config):\n",
    "    \"\"\"\n",
    "    Configuration to train on the given dataset that overrides some of the values\n",
    "    \"\"\"\n",
    "    NAME = \"damage\"\n",
    "    IMAGES_PER_GPU = 2 # GPU with 12GB memory can fit two images.\n",
    "    NUM_CLASSES = 1 + 1  # Background + damage\n",
    "    STEPS_PER_EPOCH = 10\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9 # Skip detections with < 90% confidence\n",
    "    \n",
    "\n",
    "class InferenceConfig(CustomConfig):\n",
    "    \"\"\"\n",
    "    Configuration to evaluate the model on test images\n",
    "    Set batch size to 1 (inference on one image at a time).\n",
    "    \"\"\"\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myDataset(utils.Dataset):\n",
    "\n",
    "    def load_custom(self, dataset_dir, mode):\n",
    "        \n",
    "        # Add \"damage\" class\n",
    "        self.add_class(\"damage\", 1, \"damage\")\n",
    "\n",
    "        # Train or validation dataset\n",
    "        dataset_dir = os.path.join(dataset_dir, mode)\n",
    "\n",
    "        # Load annotations (x and y coordinates of each region)\n",
    "        annotations = json.load(open(os.path.join(dataset_dir, \"via_region_data.json\")))\n",
    "        annotations = list(annotations.values())\n",
    "\n",
    "        # Skip unannotated images.\n",
    "        annotations = [a for a in annotations if a['regions']]\n",
    "\n",
    "        # Add images\n",
    "        for a in annotations:\n",
    "            # Get the x, y coordinates of polygon vertexes for each object instance\n",
    "            polygons = [r['shape_attributes'] for r in a['regions'].values()]\n",
    "\n",
    "            # retrieve the image size to convert polygons to masks.\n",
    "            image_path = os.path.join(dataset_dir, a['filename'])\n",
    "            image = skimage.io.imread(image_path)\n",
    "            height, width = image.shape[:2]\n",
    "\n",
    "            self.add_image(\n",
    "                \"damage\",\n",
    "                image_id=a['filename'],\n",
    "                path=image_path,\n",
    "                width=width, height=height,\n",
    "                polygons=polygons)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \n",
    "        # Convert polygons to a bitmap mask of shape [height, width, instance_count]\n",
    "        info = self.image_info[image_id]\n",
    "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])],\n",
    "                        dtype=np.uint8)\n",
    "        \n",
    "        for i, p in enumerate(info[\"polygons\"]):\n",
    "            # Get indexes of pixels inside the polygon and set them to 1\n",
    "            rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])\n",
    "            mask[rr, cc, i] = 1\n",
    "\n",
    "        # Return mask, and array of class IDs of each instance. Since we have\n",
    "        # one class ID only, we return an array of 1s\n",
    "        return mask.astype(np.bool), np.ones([mask.shape[-1]], dtype=np.int32)\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"damage\":\n",
    "            return info[\"path\"]\n",
    "        else:\n",
    "            super(self.__class__, self).image_reference(image_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "\n",
    "    # Training dataset.\n",
    "    dataset_train = myDataset()\n",
    "    dataset_train.load_custom(dataset, \"train\")\n",
    "    dataset_train.prepare()\n",
    "\n",
    "    # Validation dataset\n",
    "    dataset_val = myDataset()\n",
    "    dataset_val.load_custom(dataset, \"val\")\n",
    "    dataset_val.prepare()\n",
    "\n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                epochs=10,\n",
    "                layers='heads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Color masks functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_splash(image, mask):\n",
    "    \"\"\"\n",
    "    Apply color splash effect.\n",
    "    image: RGB image [height, width, 3]\n",
    "    mask: instance segmentation mask [height, width, instance count]\n",
    "\n",
    "    Returns result image.\n",
    "    \"\"\"\n",
    "    # Make a grayscale copy of the image.\n",
    "    gray = skimage.color.gray2rgb(skimage.color.rgb2gray(image)) * 255\n",
    "    # We're treating all instances as one, so collapse the mask into one layer\n",
    "    mask = (np.sum(mask, -1, keepdims=True) >= 1)\n",
    "    # Copy color pixels from the original color image where mask is set\n",
    "    if mask.shape[0] > 0:\n",
    "        splash = np.where(mask, image, gray).astype(np.uint8)\n",
    "    else:\n",
    "        splash = gray\n",
    "    return splash\n",
    "\n",
    "\n",
    "def detect_and_color_splash(model, image_path=None):\n",
    "    \"\"\"\n",
    "    Run model detection and generate the color splash effect\n",
    "    \"\"\"\n",
    "    print(\"Running on {}\".format(image_path))\n",
    "    # Read image\n",
    "    image = skimage.io.imread(image_path)\n",
    "    # Detect objects\n",
    "    r = model.detect([image], verbose=1)[0]\n",
    "    # Color splash\n",
    "    splash = color_splash(image, r['masks'])\n",
    "    # Save output\n",
    "    file_name = \"detected_damage_{}.png\".format(image_path.split(\"/\")[-1].split(\".\")[0])\n",
    "    skimage.io.imsave(file_name, splash)\n",
    "\n",
    "    print(\"Saved\", file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "config = CustomConfig()\n",
    "# config.display()\n",
    "\n",
    "# Define model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=logs)\n",
    "\n",
    "# Loading pre-trained weights excluding the last layers because they require a matching number of classes\n",
    "print(\"Loading weights from\", weights_path)\n",
    "model.load_weights(weights_path, by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "\n",
    "# Train model\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Damage detection on test images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from ./mask_rcnn_coco.h5\n",
      "Running on ./test/test1.jpg\n",
      "Processing 1 images\n",
      "image                    shape: (1415, 2119, 3)       min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 2119.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n",
      "Saved to  detected_damage_20220311T185439.png\n",
      "Running on ./test/test2.jpg\n",
      "Processing 1 images\n",
      "image                    shape: (360, 480, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n",
      "Saved to  detected_damage_20220311T185450.png\n"
     ]
    }
   ],
   "source": [
    "# Inference configuration   \n",
    "config = InferenceConfig()\n",
    "# config.display()\n",
    "\n",
    "# Create model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", config=config, model_dir=logs)\n",
    "\n",
    "# Loading pre-trained weights excluding the last layers because they require a matching number of classes\n",
    "print(\"Loading weights from\", weights_path)\n",
    "model.load_weights(weights_path, by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "\n",
    "# Evaluate model on each image of the test folder\n",
    "for filename in os.listdir(test_images):\n",
    "    \n",
    "    image = os.path.join(test_images, filename)\n",
    "    detect_and_color_splash(model, image_path=image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interview",
   "language": "python",
   "name": "interview"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
